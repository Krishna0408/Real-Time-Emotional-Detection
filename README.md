This is a Python code for performing real-time facial emotion recognition using a pre-trained deep learning model. The model is loaded from the "best_model.h5" file, which contains a neural network trained on a dataset of facial images labeled with their corresponding emotions. The code uses the OpenCV library to capture frames from the webcam, detect faces in the frames using a Haar cascade classifier, and then classify the detected face's emotion using the loaded model. The predicted emotion is displayed on the screen along with a rectangle around the detected face. The loop continues until the user presses the 'q' key, which closes the program and releases the webcam.



OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library

neural network
computer system modelled on the human brain and nervous system.

- `import os`: This is a Python built-in library for interacting with the operating system. It provides a way to access files and directories, manipulate paths, and perform various system-related tasks.

- `import cv2`: This is the OpenCV library for computer vision tasks, such as image and video processing. It provides various functions for image manipulation, object detection, and feature extraction.

- `import numpy as np`: This is a numerical computing library for Python. It provides an array object that can store and manipulate large amounts of numerical data efficiently.

- `from keras.preprocessing import image`: This is a module in the Keras deep learning library that provides image preprocessing functions, such as image resizing, cropping, and normalization.

- `import warnings`: This is a Python built-in module that allows the programmer to handle warning messages generated by the program.

- `warnings.filterwarnings("ignore")`: This line of code is used to suppress warning messages generated by the program during runtime.

- `from tensorflow.keras.utils import img_to_array`: This is a function in the Keras module of the TensorFlow library that converts an image to a NumPy array. This function is used to preprocess the image data for feeding into a neural network.

- `from keras.preprocessing.image import ImageDataGenerator`: This is a module in the Keras library that provides real-time data augmentation for image datasets during training.

- `from tensorflow.keras.utils import load_img`: This is a function in the Keras module of the TensorFlow library that loads an image file into memory as a PIL (Python Imaging Library) image.

- `from keras.models import load_model`: This is a function in the Keras library that loads a pre-trained neural network model from a saved file.

- `import numpy as np`: This is a numerical computing library for Python. It provides an array object that can store and manipulate large amounts of numerical data efficiently.

Haar Cascade is a feature-based object detection algorithm to detect objects from images. A cascade function is trained on lots of positive and negative images for detection. The algorithm does not require extensive computation and can run in real-time.


face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

This line loads a pre-trained classifier (Haar Cascade Classifier) for face detection, which is used to detect faces in the input image.

cap = cv2.VideoCapture(0)
This line initializes the video capture object for accessing the default camera (webcam) with the index '0'

while True:
    ret, test_img = cap.read()

This loop captures frames from the video input stream, reads them one by one, and sets the 'ret' flag to true if it succeeds. 'test_img' holds the captured frame.

if not ret:
    continue
If the capture fails, the loop continues to the next iteration.


gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)
This converts the color image to grayscale, which is required for face detection.


faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)
This line detects faces in the grayscale image using the pre-trained Haar Cascade Classifier. The 'detectMultiScale' function returns the coordinates and dimensions of the detected faces


for (x, y, w, h) in faces_detected:
    cv2.rectangle(test_img, (x, y), (x + w, y + h), (255, 0, 0), thickness=7)
For each detected face, this code draws a rectangle around it using the 'cv2.rectangle' function, which is passed the captured image, the top-left and bottom-right coordinates of the rectangle, and the color and thickness of the rectangle

roi_gray = gray_img[y:y + w, x:x + h]
roi_gray = cv2.resize(roi_gray, (224, 224))
This code crops the detected face region of interest (ROI) from the grayscale image, and then resizes it to the input shape required by the deep learning model (224 x 224).

img_pixels = img_to_array(roi_gray)
img_pixels = np.expand_dims(img_pixels, axis=0)
img_pixels /= 255
This code converts the ROI into a 3D array of pixels, adds an extra dimension to it, and normalizes the pixel values to be between 0 and 1. This is required for inputting the ROI into the deep learning model

predictions = model.predict(img_pixels)
This line feeds the ROI into the pre-trained deep learning model and returns a probability distribution over the emotion classes


max_index = np.argmax(predictions[0])
emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')
predicted_emotion = emotions[max_index]
This code finds the index of the maximum predicted probability and maps it to the corresponding emotion label using the 'emotions' array.

max_index = np.argmax(predictions[0])
emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')
predicted_emotion = emotions[max_index]
This code finds the index of the maximum predicted probability and maps it to the corresponding emotion label using the 'emotions' array.



